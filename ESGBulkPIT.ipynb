{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting ESG Bulk PIT Content Set- Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESG stands for Environmental, Social and (Corporate) Governance data.\n",
    "\n",
    "Refinitiv Data Platform (RDP) provides simple web based API access to a broad range of content, including ESG content and ESG content in bulk.\n",
    "\n",
    "PIT content is newly made available on RDP, we would like to discuss the recommended approach to working with this content set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time, getopt, sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Valid Credentials \n",
    "\n",
    "Valid RDP credentials are required to proceed:\n",
    "* USERNAME\n",
    "* PASSWORD\n",
    "* CLIENTID\n",
    "\n",
    "To read one's valid credentials from a file (that can be shared by many code examples), leave below code as is.\n",
    "\n",
    "To provide credentials in place:\n",
    "* replace the commented credentials with one's valid assigned credentials\n",
    "* comment the read from file step readCredsFromFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"VALIDUSER\"\n",
    "PASSWORD = \"VALIDPASSWORD\"\n",
    "CLIENT_ID = \"SELFGENERATEDCLIENTID\"\n",
    "\n",
    "def readCredsFromFile(filePathName):\n",
    "### Read valid credentials from file\n",
    "    global USERNAME, PASSWORD, CLIENT_ID\n",
    "    credFile = open(filePathName,\"r\")    # one per line\n",
    "                                                #--- RDP MACHINE ID---\n",
    "                                                #--- LONG PASSWORD---\n",
    "                                                #--- GENERATED CLIENT ID---\n",
    "\n",
    "    USERNAME = credFile.readline().rstrip('\\n')\n",
    "    PASSWORD = credFile.readline().rstrip('\\n')\n",
    "    CLIENT_ID = credFile.readline().rstrip('\\n')\n",
    "\n",
    "    credFile.close()\n",
    "\n",
    "readCredsFromFile(\"..\\creds\\credFileHuman.txt\")\n",
    "\n",
    "# Uncomment - to make sure that creds are either set in code or read in correctly\n",
    "#print(\"USERNAME=\"+str(USERNAME))\n",
    "#print(\"PASSWORD=\"+str(PASSWORD))\n",
    "#print(\"CLIENT_ID=\"+str(CLIENT_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Application Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Application Constants\n",
    "RDP_AUTH_VERSION = \"/v1\"\n",
    "RDP_ESG_BULK_VERSION = \"/v1\"\n",
    "RDP_BASE_URL = \"https://api.refinitiv.com\"\n",
    "RDP_ESG_PIT_BUCKET = \"bulk-esg\"\n",
    "CATEGORY_URL = \"/auth/oauth2\"\n",
    "ENDPOINT_URL = \"/token\"\n",
    "CLIENT_SECRET = \"\"\n",
    "TOKEN_FILE = \"token.txt\"\n",
    "SCOPE = \"trapi\"\n",
    "FILESET_ID = ''\n",
    "PACKAGE_ID = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Token Handling and Obtain a Valid Token\n",
    "\n",
    "Having a valid token is a pre-requisite to requesting of any RDP content, and will be passed into the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_ENDPOINT = RDP_BASE_URL + CATEGORY_URL + RDP_AUTH_VERSION + ENDPOINT_URL\n",
    "\n",
    "def _requestNewToken(refreshToken):\n",
    "    if refreshToken is None:\n",
    "        tData = {\n",
    "            \"username\": USERNAME,\n",
    "            \"password\": PASSWORD,\n",
    "            \"grant_type\": \"password\",\n",
    "            \"scope\": SCOPE,\n",
    "            \"takeExclusiveSignOnControl\": \"true\"\n",
    "        };\n",
    "    else:\n",
    "        tData = {\n",
    "            \"refresh_token\": refreshToken,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "        };\n",
    "\n",
    "    # Make a REST call to get latest access token\n",
    "    response = requests.post(\n",
    "        TOKEN_ENDPOINT,\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\"\n",
    "        },\n",
    "        data = tData,\n",
    "        auth = (\n",
    "            CLIENT_ID,\n",
    "            CLIENT_SECRET\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"Failed to get access token {0} - {1}\".format(response.status_code, response.text));\n",
    "\n",
    "    # Return the new token\n",
    "    return json.loads(response.text);\n",
    "\n",
    "def saveToken(tknObject):\n",
    "    tf = open(TOKEN_FILE, \"w+\");\n",
    "    print(\"Saving the new token\");\n",
    "    # Append the expiry time to token\n",
    "    tknObject[\"expiry_tm\"] = time.time() + int(tknObject[\"expires_in\"]) - 10;\n",
    "    # Store it in the file\n",
    "    json.dump(tknObject, tf, indent=4)\n",
    "    \n",
    "def getToken():\n",
    "    try:\n",
    "        print(\"Reading the token from: \" + TOKEN_FILE);\n",
    "        # Read the token from a file\n",
    "        tf = open(TOKEN_FILE, \"r+\")\n",
    "        tknObject = json.load(tf);\n",
    "\n",
    "        # Is access token valid\n",
    "        if tknObject[\"expiry_tm\"] > time.time():\n",
    "            # return access token\n",
    "            return tknObject[\"access_token\"];\n",
    "\n",
    "        print(\"Token expired, refreshing a new one...\");\n",
    "        tf.close();\n",
    "        # Get a new token from refresh token\n",
    "        tknObject = _requestNewToken(tknObject[\"refresh_token\"]);\n",
    "\n",
    "    except Exception as exp:\n",
    "        print(\"Caught exception: \" + str(exp))\n",
    "        print(\"Getting a new token using Password Grant...\");\n",
    "        tknObject = _requestNewToken(None);\n",
    "\n",
    "    # Persist this token for future queries\n",
    "    saveToken(tknObject)\n",
    "#    print(\"Token is: \" + tknObject[\"access_token\"])\n",
    "    # Return access token\n",
    "    return tknObject[\"access_token\"];\n",
    "\n",
    "accessToken = getToken();\n",
    "print(\"Have token now\");\n",
    "print(\"Token is: \" + accessToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Available ESG Bulk PIT File Sets per Package ID\n",
    "PackageID assigned to PIT content set should be known prior, at this time it's '4173-aec7-8a0b0ac9-96f9-48e83ddbd2ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "packageIdPIT = '4173-aec7-8a0b0ac9-96f9-48e83ddbd2ad'\n",
    "FILESET_ENDPOINT = RDP_BASE_URL+'/file-store'+RDP_ESG_BULK_VERSION + '/file-sets?bucket='+ RDP_ESG_PIT_BUCKET\n",
    "\n",
    "def requestFileSets(token, withNext, skipToken, attributes):   \n",
    "    global FILESET_ENDPOINT\n",
    "     \n",
    "    \n",
    "    print(\"Obtaining FileSets in ESG Bucket...\")\n",
    "  \n",
    "    FILESET_ENDPOINT = RDP_BASE_URL+'/file-store'+RDP_ESG_BULK_VERSION + '/file-sets?bucket='+ RDP_ESG_PIT_BUCKET\n",
    "    \n",
    "    querystring = {}\n",
    "    payload = \"\"\n",
    "    jsonfull = \"\"\n",
    "    jsonpartial = \"\"\n",
    "    \n",
    "    headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Authorization': \"Bearer \" + token,\n",
    "            'cache-control': \"no-cache\"\n",
    "    }\n",
    "\n",
    "    if attributes:\n",
    "        FILESET_ENDPOINT = FILESET_ENDPOINT + attributes\n",
    "    if withNext:\n",
    "        FILESET_ENDPOINT = FILESET_ENDPOINT + '&skipToken=' +skipToken\n",
    "    \n",
    "    print('GET '+FILESET_ENDPOINT )    \n",
    "    response = requests.request(\"GET\", FILESET_ENDPOINT, data=payload, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "                accessToken = getToken();     # token refresh on token expired\n",
    "                headers['Authorization'] = \"Bearer \" + accessToken\n",
    "                response = requests.request(\"GET\", FILESET_ENDPOINT, data=payload, headers=headers, params=querystring)\n",
    "         \n",
    "    print('Raw response=');\n",
    "    print(response);\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        jsonFullResp = json.loads(response.text)        \n",
    "        return jsonFullResp; \n",
    "    else:\n",
    "        return '';\n",
    "\n",
    "jsonFullResp = requestFileSets(accessToken, False, '','&packageId='+packageIdPIT);\n",
    "\n",
    "print('Parsed json response=');\n",
    "print(json.dumps(jsonFullResp, indent=2));\n",
    "print('Same response, tabular view');\n",
    "dfPIT = pd.json_normalize(jsonFullResp['value'])\n",
    "dfPIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select ESG Fileset ID\n",
    "We are going to select FileSetID of a Fileset that is most recent - with maximum \"created\" timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPITlast = dfPIT[dfPIT.created == dfPIT.created.max()]\n",
    "FILESET_ID = dfPITlast[\"id\"].iloc[0]\n",
    "print('FILESET_ID selected is: ' + FILESET_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request File IDs per selected Fileset ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILES_ENDPOINT_START = RDP_BASE_URL+'/file-store'+RDP_ESG_BULK_VERSION + '/files?filesetId='\n",
    " \n",
    "def requestFileDetails(token, fileSetId, attributes, withNext, skipToken):   \n",
    "\n",
    "    print(\"Obtaining File details for FileSet= \"+ fileSetId + \" ...\")\n",
    "    print(\"(If result is Response=400, make sure that fileSetId is set with a valid value...)\")\n",
    "    if withNext:\n",
    "        FILES_ENDPOINT = RDP_BASE_URL + skipToken\n",
    "    else:\n",
    "        FILES_ENDPOINT = FILES_ENDPOINT_START + fileSetId\n",
    "  \n",
    "    if attributes:\n",
    "        FILES_ENDPOINT = FILES_ENDPOINT + attributes\n",
    "        \n",
    "    querystring = {}\n",
    "    payload = \"\"\n",
    "    jsonfull = \"\"\n",
    "    jsonpartial = \"\"\n",
    "    \n",
    "    headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Authorization': \"Bearer \" + token,\n",
    "            'cache-control': \"no-cache\"\n",
    "    }\n",
    "        \n",
    "    response = requests.request(\"GET\", FILES_ENDPOINT, data=payload, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "                accessToken = getToken();     # token refresh on token expired\n",
    "                headers['Authorization'] = \"Bearer \" + accessToken\n",
    "                response = requests.request(\"GET\", FILES_ENDPOINT, data=payload, headers=headers, params=querystring)\n",
    "         \n",
    "    print('Raw response=');\n",
    "    print(response);\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        jsonFullResp = json.loads(response.text)        \n",
    "        return jsonFullResp; \n",
    "    else:\n",
    "        return '';\n",
    "\n",
    "jsonFullResp = requestFileDetails(accessToken, FILESET_ID, '&pageSize=100', False, '');\n",
    "\n",
    "print('Parsed json response=');\n",
    "print(json.dumps(jsonFullResp, indent=2));\n",
    "dfPart1 = pd.json_normalize(jsonFullResp['value'])\n",
    "dfPart1\n",
    "\n",
    "skipToken = jsonFullResp['@nextLink']\n",
    "skipToken\n",
    "\n",
    "jsonFullRespRemainder = requestFileDetails(accessToken, FILESET_ID, '&pageSize=100', True, skipToken);\n",
    "\n",
    "print('Parsed json response=');\n",
    "print(json.dumps(jsonFullRespRemainder, indent=2));\n",
    "dfPart2 = pd.json_normalize(jsonFullRespRemainder['value'])\n",
    "dfPart2\n",
    "\n",
    "#Put the two results together\n",
    "dfAll = dfPart1.append(dfPart2)\n",
    "dfAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify All the Latest Initialization files\n",
    "Select .F files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFull = dfAll.loc[dfAll['filename'].str.contains('\\.F\\.')]\n",
    "dfFull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify The Latest Delta Files\n",
    "Select .I files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDelta = dfAll.loc[dfAll['filename'].str.contains('\\.I\\.')]\n",
    "dfDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Download File via File Id with Redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "FILES_STREAM_ENDPOINT_START = RDP_BASE_URL+'/file-store'+RDP_ESG_BULK_VERSION + '/files/'\n",
    "\n",
    "# use valid values, obtained from the previous step\n",
    "exampleFileId = '4edd-99af-da829f42-8ddd-07fabfcddca9'  \n",
    "exampleFileName = 'RFT-ESG-Sources-Full-Init-2021-01-17-part07.jsonl.gz'\n",
    "\n",
    "def requestFileDownload(token, fileId, fileName):   \n",
    "    FILES_STREAM_ENDPOINT = FILES_STREAM_ENDPOINT_START + fileId+ '/stream'\n",
    "    print(\"Obtaining File ... \" + FILES_STREAM_ENDPOINT)\n",
    "  \n",
    "    chunk_size = 1000\n",
    "    \n",
    "    headers = {\n",
    "            'Authorization': 'Bearer ' + token,\n",
    "            'cache-control': \"no-cache\",\n",
    "            'Accept': '*/*'\n",
    "    }\n",
    "        \n",
    "    response = requests.request(\"GET\", FILES_STREAM_ENDPOINT, headers=headers, stream=True, allow_redirects=True)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "                accessToken = getToken();     # token refresh on token expired\n",
    "                headers['Authorization'] = \"Bearer \" + accessToken\n",
    "                response = requests.request(\"GET\",FILES_STREAM_ENDPOINT, headers=headers, stream=True, allow_redirects=True)\n",
    "\n",
    "         \n",
    "    print('Response code=' + str(response.status_code));\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print('Processing...')\n",
    "        with open(fileName, 'wb') as fd:\n",
    "            shutil.copyfileobj(response.raw, fd) \n",
    "        print('Look for gzipped file named: '+ fileName + ' in current directory')\n",
    "        response.connection.close()\n",
    "        \n",
    "    return; \n",
    "\n",
    "# consider below an example only\n",
    "#requestFileDownload(accessToken, exampleFileId, exampleFileName);\n",
    "#requestFileDownload(accessToken, FILE_ID, FILE_NAME);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the Latest PIT Delta Files and Request Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in dfDelta.iterrows():\n",
    "    print (index,row[\"id\"], row[\"filename\"])\n",
    "    requestFileDownload(accessToken, row[\"id\"],'.\\\\PITfiles\\\\'+row[\"filename\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the Latest PIT Full Files and Request Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in dfFull.iterrows():\n",
    "    print (index,row[\"id\"], row[\"filename\"])\n",
    "    requestFileDownload(accessToken, row[\"id\"],'.\\\\PITfiles\\\\'+row[\"filename\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get File Location (Step 1 of 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "FILES_STREAM_ENDPOINT_START = RDP_BASE_URL+'/file-store'+RDP_ESG_BULK_VERSION + '/files/'\n",
    "DIRECT_URL = ''\n",
    " \n",
    "def requestFileLocation(token, fileId):   \n",
    "    \n",
    "    FILES_STREAM_ENDPOINT = FILES_STREAM_ENDPOINT_START + fileId+ '/stream?doNotRedirect=true'    \n",
    "    print(\"Obtaining File ... \" + FILES_STREAM_ENDPOINT)\n",
    "  \n",
    "    filename = FILE_NAME\n",
    "    chunk_size = 1000\n",
    "    \n",
    "    headers = {\n",
    "            'Authorization': 'Bearer ' + token,\n",
    "            'cache-control': \"no-cache\",\n",
    "            'Accept': '*/*'\n",
    "    }\n",
    "        \n",
    "    response = requests.request(\"GET\", FILES_STREAM_ENDPOINT, headers=headers, stream=False, allow_redirects=False)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "                accessToken = getToken();     # token refresh on token expired\n",
    "                headers['Authorization'] = \"Bearer \" + accessToken\n",
    "                response = requests.request(\"GET\",FILES_STREAM_ENDPOINT, headers=headers, stream=False, allow_redirects=False)\n",
    "\n",
    "         \n",
    "    print('Response code=' + str(response.status_code));\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        jsonFullResp = json.loads(response.text)\n",
    "        print('Parsed json response=');\n",
    "        print(json.dumps(jsonFullResp, indent=2));\n",
    "        DIRECT_URL = jsonFullResp['url'];\n",
    "        print('File Direct URL is: '  +str(DIRECT_URL)+ '|||');\n",
    "        \n",
    "        return jsonFullResp['url'];\n",
    "    else:\n",
    "        return 'Error response: '+ response.text\n",
    "\n",
    "\n",
    "DIRECT_URL = requestFileLocation(accessToken, FILE_ID);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download File From File Location (Step 2 of 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "def requestDirectFileDownload(token, directUrl, fileName):   \n",
    "    \n",
    "    global DIRECT_URL\n",
    "    print(\"Obtaining File from URL... \" + directUrl)\n",
    "    \n",
    "    #Parse out URL parameters for submission into requests\n",
    "    url_obj = urlparse(DIRECT_URL)\n",
    "    parsed_params = parse_qs(url_obj.query)\n",
    "    # extract the URL without query parameters\n",
    "    parsed_url = url_obj._replace(query=None).geturl()\n",
    "\n",
    "    response = requests.get(parsed_url, params=parsed_params,stream=True)\n",
    "        \n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "                accessToken = getToken();     # token refresh on token expired\n",
    "                headers['Authorization'] = \"Bearer \" + accessToken\n",
    "                response = requests.get(parsed_url, params=query)\n",
    "\n",
    "         \n",
    "    print('Response code=' + str(response.status_code));        \n",
    "  \n",
    "    filename = 'another_'+fileName    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print('Processing...')\n",
    "        with open(filename, 'wb') as fd:\n",
    "            shutil.copyfileobj(response.raw, fd) \n",
    "\n",
    "        print('Look for gzipped file named: '+ filename + ' in current directory')\n",
    "        response.connection.close()\n",
    "        \n",
    "    return; \n",
    "\n",
    "\n",
    "requestDirectFileDownload(accessToken, DIRECT_URL, FILE_NAME);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
